{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {
    "id": "f35354cd"
   },
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {
    "id": "560fb3ff"
   },
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "* PEFT technique:\n",
    "* Model:\n",
    "* Evaluation approach:\n",
    "* Fine-tuning dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3228bff1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3228bff1",
    "outputId": "7efa309d-b2ef-4749-f601-b463ae3f4579"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.36.0)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.18.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.41.1)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.25.0)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/student/.local/lib/python3.10/site-packages (from evaluate) (0.21.4)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/student/.local/lib/python3.10/site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/student/.local/lib/python3.10/site-packages (from evaluate) (4.66.2)\n",
      "Requirement already satisfied: pandas in /home/student/.local/lib/python3.10/site-packages (from evaluate) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/student/.local/lib/python3.10/site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: packaging in /home/student/.local/lib/python3.10/site-packages (from evaluate) (24.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/student/.local/lib/python3.10/site-packages (from evaluate) (2024.2.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/student/.local/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: filelock in /home/student/.local/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: typing-extensions in /home/student/.local/lib/python3.10/site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/student/.local/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/student/.local/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/student/.local/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/student/.local/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/student/.local/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/student/.local/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/student/.local/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/student/.local/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/student/.local/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/student/.local/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/student/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Installing collected packages: evaluate\n",
      "\u001b[33m  WARNING: The script evaluate-cli is installed in '/home/student/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed evaluate-0.4.3\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers datasets peft bitsandbytes accelerate\n",
    "!pip install evaluate transformers datasets torch bitsandbytes accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fe4f903",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/student/.local/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {
    "id": "de8d76bb"
   },
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "BhINGgqwHb8H",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BhINGgqwHb8H",
    "outputId": "348a0b04-ae4a-4be0-d3fb-cc3bfaec1eea"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3oYkOrzWHb_P",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3oYkOrzWHb_P",
    "outputId": "c4cd2716-3128-438e-f74f-a6d5fd271bbe"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3f6ca41e51e4a21bfca0400109b4e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c8fe359e30f45f2bbdaca6aea0195f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8844fee4db6401db80fc21cff459dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d006e1c6424c82bb64d437b6ce09b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e16063465e4b46f7973548247c3c7789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load pretrained model and tokenizer\n",
    "model_name = \"bert-base-uncased\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "uZSbWDP_HcCp",
   "metadata": {
    "id": "uZSbWDP_HcCp"
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"imdb\")\n",
    "small_train_dataset = dataset[\"train\"].shuffle(seed=42).select(range(10000))\n",
    "small_test_dataset = dataset[\"test\"].shuffle(seed=42).select(range(2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f56a4f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "NIfncFGJHcGi",
   "metadata": {
    "id": "NIfncFGJHcGi"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2fb9a4f6c0442ba8ca8b8979da8ff78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "847506d7b8954f9bb184708a24efec8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenization function\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "# Apply tokenization\n",
    "tokenized_train = small_train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_test = small_test_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "OBez4o3NJbqz",
   "metadata": {
    "id": "OBez4o3NJbqz"
   },
   "outputs": [],
   "source": [
    "tokenized_train.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "tokenized_test.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "RyDaWmeUJbtY",
   "metadata": {
    "id": "RyDaWmeUJbtY"
   },
   "outputs": [],
   "source": [
    "# Define evaluation metric\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cxCCw_c2JbwO",
   "metadata": {
    "id": "cxCCw_c2JbwO"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9JeepVroKJfl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9JeepVroKJfl",
    "outputId": "551db388-0bbf-482f-a423-c3b729642b80"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained Model Evaluation Results: {'eval_loss': 0.6863271594047546, 'eval_accuracy': 0.551, 'eval_runtime': 6.6746, 'eval_samples_per_second': 299.642, 'eval_steps_per_second': 37.455}\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    eval_dataset=tokenized_test,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "pretrained_eval_results = trainer.evaluate()\n",
    "print(\"Pretrained Model Evaluation Results:\", pretrained_eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {
    "id": "4d52a229"
   },
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "RSoa5QBhHkZH",
   "metadata": {
    "id": "RSoa5QBhHkZH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 589,824 || all params: 110,075,140 || trainable%: 0.5358376105631117\n"
     ]
    }
   ],
   "source": [
    "# Required imports for PEFT\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from bitsandbytes.optim import AdamW8bit\n",
    "\n",
    "# Create PEFT model with LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=16,  # Rank of the low-rank update\n",
    "    lora_alpha=32,  # Scaling factor\n",
    "    target_modules=[\"query\", \"value\"],  # Target attention layers in BERT\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\",\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, lora_config)\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3FsqzrsqHkcP",
   "metadata": {
    "id": "3FsqzrsqHkcP"
   },
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./peft_results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,  # At least 1 epoch\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./peft_logs\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "# Set up trainer with QLoRA (8-bit optimizer)\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    compute_metrics=compute_metrics,\n",
    "    optimizers=(AdamW8bit(peft_model.parameters(), lr=2e-5), None),  # QLoRA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "lXJhUXKgHkfY",
   "metadata": {
    "id": "lXJhUXKgHkfY"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6250' max='6250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6250/6250 07:23, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.433655</td>\n",
       "      <td>0.812000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.400200</td>\n",
       "      <td>0.384520</td>\n",
       "      <td>0.837000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.391600</td>\n",
       "      <td>0.369960</td>\n",
       "      <td>0.844000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.376900</td>\n",
       "      <td>0.362441</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.359700</td>\n",
       "      <td>0.363849</td>\n",
       "      <td>0.847500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEFT model saved to ./peft_model_weights\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "# Save the PEFT model weights\n",
    "output_dir = \"./peft_model_weights\"\n",
    "peft_model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)  # Optional: save tokenizer\n",
    "print(f\"PEFT model saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {
    "id": "615b12c6"
   },
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf08d77",
   "metadata": {
    "id": "daf08d77"
   },
   "source": [
    "#### Load the fine-Tuned LoRA Model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1690e598",
   "metadata": {
    "id": "1690e598"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Required imports for loading PEFT model\n",
    "from peft import PeftModel\n",
    "\n",
    "# Load the saved PEFT model\n",
    "loaded_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "loaded_peft_model = PeftModel.from_pretrained(loaded_model, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "m1ne2S7iHlVa",
   "metadata": {
    "id": "m1ne2S7iHlVa"
   },
   "outputs": [],
   "source": [
    "# Set up trainer for evaluation\n",
    "trainer = Trainer(\n",
    "    model=loaded_peft_model,\n",
    "    args=training_args,\n",
    "    eval_dataset=tokenized_test,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "OdTKlwJHHlYT",
   "metadata": {
    "id": "OdTKlwJHHlYT"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuned Model Evaluation Results: {'eval_loss': 0.3624410331249237, 'eval_accuracy': 0.85, 'eval_runtime': 6.3049, 'eval_samples_per_second': 317.213, 'eval_steps_per_second': 39.652}\n",
      "\n",
      "Comparison of Pretrained vs Fine-Tuned Model:\n",
      "Pretrained Accuracy: 0.5300\n",
      "Fine-Tuned Accuracy: 0.8500\n"
     ]
    }
   ],
   "source": [
    "# Evaluate fine-tuned model\n",
    "finetuned_results = trainer.evaluate()\n",
    "print(\"Fine-Tuned Model Evaluation Results:\", finetuned_results)\n",
    "\n",
    "# Compare results\n",
    "print(\"\\nComparison of Pretrained vs Fine-Tuned Model:\")\n",
    "print(f\"Pretrained Accuracy: {pretrained_results['eval_accuracy']:.4f}\")\n",
    "print(f\"Fine-Tuned Accuracy: {finetuned_results['eval_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4718c295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Pretrained Model Prediction for 'First there was Tsui Hark's Zu Warriors (2001), which is visually ground-breaking, but much lacking in the acting and writing departments, now this movie, which is visually almost as good as Zu (though no longer ground-breaking), but is even worse in the acting and writing departments. It's really sad that there seems to be an almost complete lack of acting and writing talents in the HK movie industry. I guess you need to understand Cantonese to understand how bad and vulgar the dialogs in the movie really are. It's like some delinquent kids talking in the street, it's that bad. To make it worse, the actors and actresses themselves look like delinquent kids, and can't act even if their life depend on it. I understand that this movie is supposed to be a comedy aimed at the younger generation in HK, but has HK youths really become so brain-dead that they can't appreciate anything but such juvenile and vulgar acting/writing? If that's the case, it makes me ashamed to be from HK.<br /><br />I wish HK movie makers will learn some lessons from directors like Zhang Yi-Mou or Ang Lee, and finally make a movie that's both visually stunning as well as competent and mature in the acting and writing departments. And stop using young singers/idols/heartthrobs as actors because they can't act however many fans they may have in HK!': Negative\n",
      "Fine-Tuned Model Prediction for 'First there was Tsui Hark's Zu Warriors (2001), which is visually ground-breaking, but much lacking in the acting and writing departments, now this movie, which is visually almost as good as Zu (though no longer ground-breaking), but is even worse in the acting and writing departments. It's really sad that there seems to be an almost complete lack of acting and writing talents in the HK movie industry. I guess you need to understand Cantonese to understand how bad and vulgar the dialogs in the movie really are. It's like some delinquent kids talking in the street, it's that bad. To make it worse, the actors and actresses themselves look like delinquent kids, and can't act even if their life depend on it. I understand that this movie is supposed to be a comedy aimed at the younger generation in HK, but has HK youths really become so brain-dead that they can't appreciate anything but such juvenile and vulgar acting/writing? If that's the case, it makes me ashamed to be from HK.<br /><br />I wish HK movie makers will learn some lessons from directors like Zhang Yi-Mou or Ang Lee, and finally make a movie that's both visually stunning as well as competent and mature in the acting and writing departments. And stop using young singers/idols/heartthrobs as actors because they can't act however many fans they may have in HK!': Negative\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def predict_sentence(sentence, model, tokenizer, device):\n",
    "    # Tokenize the input sentence\n",
    "    inputs = tokenizer(sentence, truncation=True, padding=\"max_length\", max_length=64, return_tensors=\"pt\")\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}  # Move to device\n",
    "    \n",
    "    # Perform inference\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        prediction = torch.argmax(logits, dim=-1).item()\n",
    "    \n",
    "    # Map prediction to label\n",
    "    label = \"Positive\" if prediction == 1 else \"Negative\"\n",
    "    return label\n",
    "\n",
    "# Test sentence (you can change this)\n",
    "test_sentence = dataset['test'][988]['text']\n",
    "\n",
    "# Test with pretrained model\n",
    "pretrained_prediction = predict_sentence(test_sentence, model, tokenizer, device)\n",
    "print(f\"\\nPretrained Model Prediction for '{test_sentence}': {pretrained_prediction}\")\n",
    "\n",
    "# Test with fine-tuned model\n",
    "finetuned_prediction = predict_sentence(test_sentence, loaded_peft_model, tokenizer, device)\n",
    "print(f\"Fine-Tuned Model Prediction for '{test_sentence}': {finetuned_prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b9cb51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
